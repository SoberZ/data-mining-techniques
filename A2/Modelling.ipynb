{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# user based collaborative filtering\n",
    "class CollaborativeFiltering:\n",
    "    \n",
    "    # we need more search features\n",
    "    # we can remove all hotel features\n",
    "    def __init__(self):\n",
    "        self.search_features = [\"srch_adults_count\", \"srch_saturday_night_bool\", \"site_id\", \"visitor_location_country_id\", \"srch_length_of_stay\", \"srch_room_count\"]\n",
    "    \n",
    "    def cos_sim(self, user_data, test_data):\n",
    "        categorical = [\"site_id\", \"visitor_location_country_id\"]\n",
    "        user_categorical, user_numeric = user_data[categorical] , user_data.drop(categorical)\n",
    "        test_categorical, test_numeric = test_data[categorical], test_data.drop(categorical)\n",
    "        \n",
    "        # for numeric calc cos_sim\n",
    "        a = user_numeric.to_numpy()\n",
    "        b = test_numeric.to_numpy()\n",
    "        \n",
    "        cos_sim_score = dot(a, b)/(norm(a)*norm(b))\n",
    "        \n",
    "        # for cateforical_data increase cos_sim_score if it matches\n",
    "        for idx, col in enumerate(user_categorical):\n",
    "            if user_categorical[idx] == test_categorical[idx]:\n",
    "                cos_sim_score += 0.15\n",
    "    \n",
    "        return cos_sim_score\n",
    "    \n",
    "    def get_cosine_similarities(self, train_data, user_data):\n",
    "        cosine_scores = []\n",
    "        for idx, t_data in train_data.iterrows():\n",
    "            cosine_scores.append((self.cos_sim(user_data, t_data) , idx))\n",
    "            \n",
    "        return sorted(cosine_scores, reverse=True)\n",
    "    \n",
    "    def find_n_nearest_searches(self, user_data, n, hotel_id):\n",
    "        # take only those users who have data for this hotel\n",
    "        train_data = self.train_data.loc[self.train_data[\"prop_id\"] == hotel_id]\n",
    "        train_data = train_data[self.search_features]\n",
    "        # get n best rows (with highest cosine similiarity)\n",
    "        similiarities = self.get_cosine_similarities(train_data, user_data)[:n]\n",
    "        idx = [i[1] for i in similiarities]\n",
    "        return self.train_data.iloc[idx]\n",
    "        \n",
    "    def score_function(self, n_nearest_searches):\n",
    "        if n_nearest_searches.empty:\n",
    "            return -10\n",
    "        score = 0\n",
    "        b_w = 5 # booking weight\n",
    "        for _, x in n_nearest_searches.iterrows():\n",
    "            score += b_w * x[\"booking_bool\"] + x[\"click_bool\"] - x[\"position\"]\n",
    "        # return avg score \n",
    "        return score/len(n_nearest_searches)\n",
    "    \n",
    "    def fit(self, train_data, test_data, n=5):\n",
    "        self.train_data = train_data\n",
    "        output_list = []\n",
    "        # for every user search\n",
    "        with open('cf.csv', 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"srch_id\", \"prop_id\"])\n",
    "            for srch_id in test_data[\"srch_id\"].unique():\n",
    "                user_searches = test_data.loc[test_data[\"srch_id\"] == srch_id]\n",
    "                hotel_scores = []\n",
    "                user_data = user_searches[self.search_features].iloc[0]\n",
    "                for idx, search in user_searches.iterrows():\n",
    "                    # find n nearest users user_data + search_specific_data\n",
    "                    hotel_id = search[\"prop_id\"]\n",
    "                    # n nearest searches that scored a given hotel\n",
    "                    n_nearest_searches = self.find_n_nearest_searches(user_data, n, hotel_id)\n",
    "            \n",
    "                    score = self.score_function(n_nearest_searches)\n",
    "                    hotel_scores.append((score, hotel_id))\n",
    "\n",
    "                # ordered list of hotel_ids w.r.t. scores\n",
    "                hotel_scores = sorted(hotel_scores, reverse=True)\n",
    "                # only save hotel ids\n",
    "                hotel_scores = [[srch_id, int(h[1])] for h in hotel_scores]\n",
    "                writer.writerows(hotel_scores)\n",
    "                # output_list += hotel_scores\n",
    "\n",
    "            return output_list\n",
    "    \n",
    "    def eval(self, train_data, test_data):\n",
    "        pass\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/kuba/VU/DMT/data-mining-techniques/A2/100k_train_data.csv\")\n",
    "test_data = pd.read_csv(\"/Users/kuba/VU/DMT/data-mining-techniques/A2/processed_test_data.csv\")\n",
    "cf = CollaborativeFiltering()\n",
    "out = cf.fit(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55856b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random ordering as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37625113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "def random_ordering(test_data):\n",
    "    with open('sub_random.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"srch_id\", \"prop_id\"])\n",
    "        for srch_id in test_data[\"srch_id\"].unique():\n",
    "            search_list = []\n",
    "            user_searches = test_data.loc[test_data[\"srch_id\"] == srch_id]\n",
    "            for idx, search in user_searches.iterrows():\n",
    "                hotel_id = search[\"prop_id\"]\n",
    "                search_list.append([srch_id, int(hotel_id)])\n",
    "\n",
    "            random.shuffle(search_list)\n",
    "            writer.writerows(search_list)\n",
    "\n",
    "random_ordering(test_data)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a985ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def eval(predicted_ranking, actual_ranking, n=5):\n",
    "    \n",
    "    idcg = 5\n",
    "    for i in range(2, n + 1):\n",
    "        idcg += 1/math.log2(i + 1)\n",
    "        \n",
    "    i = 1\n",
    "    prev = predicted_ranking[0][0] # srch_id\n",
    "    all_ndcg = []\n",
    "    dcg = 0\n",
    "    \n",
    "    for row in predicted_ranking:\n",
    "    \n",
    "        if row[0] != prev:\n",
    "            i = 1\n",
    "            dcg = 0\n",
    "            \n",
    "        # take only first n values per search\n",
    "        if i < n + 1:\n",
    "            hotel_id = row[1]\n",
    "            # check relevance score based on if hotel was booked\n",
    "            relevance_score = 0\n",
    "            if actual_ranking[actual_ranking['srch_id' == row[0]] && actual_ranking['prop_id' == hotel_id]]['book_bool'] == 1:\n",
    "                relevance_score = 5\n",
    "                # chceck relevance score based on if hotel was clicked\n",
    "            elif actual_ranking[actual_ranking['srch_id' == row[0]] && actual_ranking['prop_id' == hotel_id]]['click_bool'] == 1:\n",
    "                relevance_score = 1\n",
    "                \n",
    "            # calculate dcg iteratively per value\n",
    "            dcg += relevance_score/math.log2(i+1)\n",
    "\n",
    "        # if last partial score for dcg added then normalize and add to all ndcg list\n",
    "        if i == n:\n",
    "            # normalize\n",
    "            ndcg = dcg/idcg\n",
    "            all_ndcg.append(ndcg)\n",
    "            \n",
    "        prev = row[0]\n",
    "        i+= 1\n",
    "\n",
    "    return sum(all_ndcg)/len(all_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d35bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('split_train_data_100k.csv')\n",
    "test_data_with_labels = pd.read_csv('split_test_data_100k.csv')\n",
    "test_data_inference = pd.read_csv('split_test_inference_data_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ca430",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CollaborativeFiltering()\n",
    "out = cf.fit(train_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
